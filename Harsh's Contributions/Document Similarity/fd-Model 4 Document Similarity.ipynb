{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning (ML) is the study of computer algorithms that improve automatically through experience.[1] It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\\n\\nA subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[4][5] In its application across business problems, machine learning is also referred to as predictive analytics.']\n"
     ]
    }
   ],
   "source": [
    "file_docs = []\n",
    "\n",
    "with open ('sample1.txt') as f:\n",
    "    tokens = f.read()\n",
    "    file_docs.append(tokens)\n",
    "\n",
    "print(file_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=file_docs\n",
    "search_terms = 'machine learning'\n",
    "# search_terms = 'tomato'\n",
    "# search_terms = 'sewing machine'\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "vectors = vectorizer.fit_transform([search_terms] + documents)\n",
    "\n",
    "# Calculate the word frequency, and calculate the cosine similarity of the search terms to the documents\n",
    "cosine_similarities = linear_kernel(vectors[0:1], vectors).flatten()\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]  # convert back to native Python dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5842832127691175,)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top-scoring results and their titles\n",
    "scores = [(score) for score in zip(document_scores)]\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tryout 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    \"\"\"\n",
    "    Interface to the WordNet lemmatizer from nltk\n",
    "    \"\"\"\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'wa', 'raining', 'cat', 'and', 'dog', 'in', 'FooBar']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=LemmaTokenizer()\n",
    "\n",
    "tokenizer('It was raining cats and dogs in FooBar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning (ML) is the study of computer algorithms that improve automatically through experience.[1] It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\\n\\nA subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[4][5] In its application across business problems, machine learning is also referred to as predictive analytics.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('sample1.txt') as f:\n",
    "    tokens=f.read()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.557067649429456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=[tokens]\n",
    "search_terms = 'machine learning is a study that improves automatically such as email filtering'\n",
    "# search_terms = 'sewing machine'\n",
    "\n",
    "# Initialise TfidfVectorizer with the LemmaTokenizer. Also need to lemmatize the stop words as well\n",
    "token_stop = tokenizer(' '.join(stop_words))\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer)\n",
    "\n",
    "# Calculate the word frequency, and calculate the cosine similarity of the search terms to the documents\n",
    "vectors = vectorizer.fit_transform([search_terms] + documents)\n",
    "cosine_similarities = linear_kernel(vectors[0:1], vectors).flatten()\n",
    "\n",
    "document_scores = [item.item() for item in cosine_similarities[1:]]  # convert back to native Python dtypes\n",
    "\n",
    "scores = [(score) for score in zip(document_scores)]\n",
    "perc_scores=scores[0][0]*100\n",
    "perc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning is a study that improves automatically'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms = ['machine learning is a study that improves automatically','machine learning study email']\n",
    "search_terms[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  Corupus : 36.56 %\n",
      "2  Corupus : 36.56 %\n",
      "3  Corupus : 52.42 %\n",
      "4  Corupus : 100.0 %\n"
     ]
    }
   ],
   "source": [
    "search_terms = ['machine learning is a study that improves automatically such as email filtering','machine learning is a study that improves automatically such as email filtering','machine learning','Machine learning (ML) is the study of computer algorithms that improve automatically through experience.[1] It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\\n\\nA subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[4][5] In its application across business problems, machine learning is also referred to as predictive analytics.']\n",
    "# search_terms = 'sewing machine'\n",
    "\n",
    "# Initialise TfidfVectorizer with the LemmaTokenizer. Also need to lemmatize the stop words as well\n",
    "token_stop = tokenizer(' '.join(stop_words))\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer)\n",
    "\n",
    "# Calculate the word frequency, and calculate the cosine similarity of the search terms to the documents\n",
    "\n",
    "for i in range(len(search_terms)):\n",
    "    vectors = vectorizer.fit_transform([search_terms[i]] + documents)\n",
    "    cosine_similarities = linear_kernel(vectors[0:1], vectors).flatten()\n",
    "\n",
    "    document_scores = [item.item() for item in cosine_similarities[1:]]  # convert back to native Python dtypes\n",
    "\n",
    "    scores = [(score) for score in zip(document_scores)]\n",
    "    perc_scores=scores[0][0]*100\n",
    "    print(i+1,\" Corupus :\",round(perc_scores,2),\"%\")\n",
    "    \n",
    "#perc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_similarity_score(actual,query):\n",
    "    class LemmaTokenizer:\n",
    "        \n",
    "   \n",
    "        ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`']\n",
    "        def __init__(self):\n",
    "            self.wnl = WordNetLemmatizer()\n",
    "        def __call__(self, doc):\n",
    "            return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]\n",
    "\n",
    "    tokenizer=LemmaTokenizer()\n",
    "    with open (actual) as f:\n",
    "        tokens=f.read()\n",
    "    #tokenizer(tokens)\n",
    "    \n",
    "    documents=tokens\n",
    "    search_terms = query\n",
    "    # search_terms = 'sewing machine'\n",
    "\n",
    "    # Initialise TfidfVectorizer with the LemmaTokenizer. Also need to lemmatize the stop words as well\n",
    "    token_stop = tokenizer(' '.join(stop_words))\n",
    "    vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer)\n",
    "\n",
    "    # Calculate the word frequency, and calculate the cosine similarity of the search terms to the documents\n",
    "\n",
    "    for i in range(len(search_terms)):\n",
    "        \n",
    "        vectors = vectorizer.fit_transform([search_terms[i]] + [documents])\n",
    "        cosine_similarities = linear_kernel(vectors[0:1], vectors).flatten()\n",
    "\n",
    "        document_scores = [item.item() for item in cosine_similarities[1:]]  # convert back to native Python dtypes\n",
    "\n",
    "        scores = [(score) for score in zip(document_scores)]\n",
    "        perc_scores=scores[0][0]*100\n",
    "        print(i+1,\" Corupus :\",round(perc_scores,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actual='sample1.txt'\n",
    "query=['machine learning is a study that improves automatically such as email filtering','machine learning is a study that improves automatically such as email filtering','machine learning','Machine learning (ML) is the study of computer algorithms that improve automatically through experience.[1] It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\\n\\nA subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[4][5] In its application across business problems, machine learning is also referred to as predictive analytics.']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  Corupus : 36.56 %\n",
      "2  Corupus : 36.56 %\n",
      "3  Corupus : 52.42 %\n",
      "4  Corupus : 100.0 %\n"
     ]
    }
   ],
   "source": [
    "get_similarity_score(actual,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
